{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [1, 2], [1, 3], [1, 0], [2, 1], [2, 3], [2, 0], [3, 1], [3, 2], [3, 0], [4, 11], [4, 12], [4, 13], [4, 14], [4, 15], [4, 16], [4, 5], [4, 0], [4, 6], [4, 7], [5, 4], [5, 0], [5, 6], [5, 7], [6, 17], [6, 18], [6, 19], [6, 20], [6, 7], [6, 21], [6, 4], [6, 5], [6, 0], [6, 7], [6, 22], [6, 20], [7, 23], [7, 24], [7, 25], [7, 20], [7, 6], [7, 21], [7, 4], [7, 5], [7, 0], [7, 6], [7, 26], [7, 27], [7, 28], [7, 29], [7, 30], [7, 31], [7, 32], [7, 33], [8, 9], [8, 0], [8, 10], [9, 8], [9, 0], [9, 10], [10, 8], [10, 9], [10, 0], [10, 34], [10, 35], [10, 36]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15", "16": "16", "17": "17", "18": "18", "19": "19", "20": "20", "21": "21", "22": "22", "23": "23", "24": "24", "25": "25", "26": "26", "27": "27", "28": "28", "29": "29", "30": "30", "31": "31", "32": "32", "33": "33", "34": "34", "35": "35", "36": "36"}, "count": 3, "cite": 22, "position": 3.3333333333333335, "connect": 1.0, "totalConnect": 1.5, "totalCount": 0.7297297297297297, "totalCite": 5.074074074074074, "totalPosition": 4.555555555555555, "paper": [{"title": "Comparing Similarity Perception in Time Series Visualizations", "author": ["Gogolouis,Anna", "Tsandilas,Theophanis", "Palpanas,Themis", "Bezerianos,Anastasia"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865077", "keywords": "", "abstract": "A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.", "cite": 8, "year": "2019"}, {"title": "Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches", "author": ["Blascheck,Tanja", "Besancon,Lonni", "Bezerianos,Anastasia", "Lee,Bongshin", "Isenberg,Petra"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865142", "keywords": "", "abstract": "We present the results of two perception studies to assess how quickly people can perform a simple data comparison task for small-scale visualizations on a smartwatch. The main goal of these studies is to extend our understanding of design constraints for smartwatch visualizations. Previous work has shown that a vast majority of smartwatch interactions last under 5 s. It is still unknown what people can actually perceive from visualizations during such short glances, in particular with such a limited display space of smartwatches. To shed light on this question, we conducted two perception studies that assessed the lower bounds of task time for a simple data comparison task. We tested three chart types common on smartwatches: bar charts, donut charts, and radial bar charts with three different data sizes: 7, 12, and 24 data values. In our first study, we controlled the differences of the two target bars to be compared, while the second study varied the difference randomly. For both studies, we found that participants performed the task on average in < 300 ms for the bar chart, < 220 ms for the donut chart, and in <1780 ms for the radial bar chart. Thresholds in the second study per chart type were on average 1.14-1.3x higher than in the first study. Our results show that bar and donut charts should be preferred on smartwatch displays when quick data comparisons are necessary.", "cite": 6, "year": "2019"}, {"title": "Mitigating the Attraction Effect with Visualizations", "author": ["Dimara,Evanthia", "Bailly,Gilles", "Bezerianos,Anastasia", "Franconeri,Steven"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865233", "keywords": "", "abstract": "Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions.", "cite": 8, "year": "2019"}], "name": "Bezerianos,Anastasia", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}, {"id": "16"}, {"id": "17"}, {"id": "18"}, {"id": "19"}, {"id": "20"}, {"id": "21"}, {"id": "22"}, {"id": "23"}, {"id": "24"}, {"id": "25"}, {"id": "26"}, {"id": "27"}, {"id": "28"}, {"id": "29"}, {"id": "30"}, {"id": "31"}, {"id": "32"}, {"id": "33"}, {"id": "34"}, {"id": "35"}, {"id": "36"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "2", "target": "3"}, {"source": "4", "target": "11"}, {"source": "4", "target": "12"}, {"source": "4", "target": "13"}, {"source": "4", "target": "14"}, {"source": "4", "target": "15"}, {"source": "4", "target": "16"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "4", "target": "7"}, {"source": "5", "target": "6"}, {"source": "5", "target": "7"}, {"source": "6", "target": "17"}, {"source": "6", "target": "18"}, {"source": "6", "target": "19"}, {"source": "6", "target": "20"}, {"source": "6", "target": "7"}, {"source": "6", "target": "21"}, {"source": "6", "target": "22"}, {"source": "7", "target": "23"}, {"source": "7", "target": "24"}, {"source": "7", "target": "25"}, {"source": "7", "target": "20"}, {"source": "7", "target": "21"}, {"source": "7", "target": "26"}, {"source": "7", "target": "27"}, {"source": "7", "target": "28"}, {"source": "7", "target": "29"}, {"source": "7", "target": "30"}, {"source": "7", "target": "31"}, {"source": "7", "target": "32"}, {"source": "7", "target": "33"}, {"source": "8", "target": "9"}, {"source": "8", "target": "10"}, {"source": "9", "target": "10"}, {"source": "10", "target": "34"}, {"source": "10", "target": "35"}, {"source": "10", "target": "36"}], "year": 2019, "authorId": {"0": "Bezerianos,Anastasia", "1": "Gogolouis,Anna", "2": "Tsandilas,Theophanis", "3": "Palpanas,Themis", "4": "Blascheck,Tanja", "5": "Besancon,Lonni", "6": "Lee,Bongshin", "7": "Isenberg,Petra", "8": "Dimara,Evanthia", "9": "Bailly,Gilles", "10": "Franconeri,Steven", "11": "Vermeulen,LindsayMacDonald", "12": "Vermeulen,Jo", "13": "Perin,Charles", "14": "Willett,Wesley", "15": "Ertl,Thomas", "16": "Carpendale,Sheelagh", "17": "Jo,Jaemin", "18": "Lyi,Sehi", "19": "Seo,Jinwook", "20": "Brehmer,Matthew", "21": "Choe,EunKyoung", "22": "Ren,Donghao", "23": "Tovanich,Natkamon", "24": "Heulot,Nicolas", "25": "Fekete,Jean-Daniel", "26": "Chang,Remco", "27": "Dwyer,Tim", "28": "Fujishiro,Issei", "29": "Franconeri,Steve", "30": "Qu,Huamin", "31": "Schreck,Tobias", "32": "Weiskopf,Daniel", "33": "Weber,GuntherH.", "34": "Ondov,Brian", "35": "Jardine,Nicole", "36": "Elmqvist,Niklas"}}