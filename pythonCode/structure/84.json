{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 4], [0, 7], [0, 8], [0, 9], [0, 10], [1, 2], [1, 3], [1, 0], [1, 4], [2, 1], [2, 3], [2, 0], [2, 4], [2, 11], [2, 10], [3, 1], [3, 2], [3, 0], [3, 4], [3, 11], [3, 12], [3, 13], [3, 14], [3, 10], [4, 1], [4, 2], [4, 3], [4, 0], [4, 5], [4, 0], [4, 6], [5, 0], [5, 6], [5, 4], [6, 5], [6, 0], [6, 4], [4, 1], [4, 2], [4, 3], [4, 0], [4, 5], [4, 0], [4, 6], [7, 8], [7, 9], [7, 0], [7, 10], [8, 7], [8, 9], [8, 0], [8, 10], [9, 7], [9, 8], [9, 0], [9, 10], [10, 11], [10, 2], [10, 7], [10, 8], [10, 9], [10, 0], [10, 3], [10, 11], [10, 12], [10, 13], [10, 14]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14"}, "count": 3, "cite": 1, "position": 3.3333333333333335, "connect": 1.1, "totalConnect": 2.0277777777777777, "totalCount": 0.3333333333333333, "totalCite": 1.0, "totalPosition": 4.6, "paper": [{"title": "CMed: Crowd Analytics for Medical Imaging Data.", "author": ["Park,JiHwan", "Nadeem,Saad", "Boorboor,Saeed", "Marino,Joseph", "Kaufman,ArieE"], "soname": "IEEE transactions on visualization and computer graphics", "DOI": "10.1109/TVCG.2019.2953026", "keywords": "", "abstract": "We present a visual analytics framework, CMed, for exploring medical image data annotations acquired from crowdsourcing. CMed can be used to visualize, classify, and filter crowdsourced clinical data based on a number of different metrics such as detection rate, logged events, and clustering of the annotations. CMed provides several interactive linked visualization components to analyze the crowd annotation results for a particular video and the associated workers. Additionally, all results of an individual worker can be inspected using multiple linked views in our CMed framework. We allow a crowdsourcing application analyst to observe patterns and gather insights into the crowdsourced medical data, helping him/her design future crowdsourcing applications for optimal output from the workers. We demonstrate the efficacy of our framework with two medical crowdsourcing studies: polyp detection in virtual colonoscopy videos and lung nodule detection in CT thin-slab maximum intensity projection videos. We also provide experts' feedback to show the effectiveness of our framework. Lastly, we share the lessons we learned from our framework with suggestions for integrating our framework into a clinical workflow.", "cite": 0, "year": "2019"}, {"title": "Visual Analysis of a Computer-Aided Diagnosis System for Pancreatic Lesions.", "author": ["Dmitriev,Konstantin", "Marino,Joseph", "Baker,Kevin", "Kaufman,ArieE"], "soname": "IEEE transactions on visualization and computer graphics", "DOI": "10.1109/TVCG.2019.2947037", "keywords": "", "abstract": "Machine learning is a powerful and effective tool for medical image analysis to perform computer-aided diagnosis (CAD). Having great potential in improving the accuracy of a diagnosis, CAD systems are often analyzed in terms of the final accuracy, leading to a limited understanding of the internal decision process, impossibility to gain insights, and ultimately to skepticism from clinicians. We present a visual analysis approach to uncover the decision-making process of a CAD system for classifying pancreatic cystic lesions. This CAD algorithm consists of two distinct components: random forest (RF), which classifies a set of predefined features, including demographic features, and a convolutional neural network (CNN), which analyzes radiological features of the lesions. We study the class probabilities generated by the RF and the semantical meaning of the features learned by the CNN. We also use an eye tracker to better understand which radiological features are particularly useful for a radiologist to make a diagnosis and to quantitatively compare with the features that lead the CNN to its final classification decision. Additionally, we evaluate the effects and benefits of supplying the CAD system with a case-based \"visual aid\" in a second-reader setting.", "cite": 0, "year": "2019"}, {"title": "Immersive Virtual Colonoscopy", "author": ["Mirhosseini,Seyedkoosha", "Gutenko,Ievgeniia", "Ojal,Sushant", "Marino,Joseph", "Kaufman,Arie"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2019.2898763", "keywords": "", "abstract": "Virtual colonoscopy (VC) is a non-invasive screening tool for colorectal polyps which employs volume visualization of a colon model reconstructed from a CT scan of the patient's abdomen. We present an immersive analytics system for VC which enhances and improves the traditional desktop VC through the use of VR technologies. Our system, using a head-mounted display (HMD), includes all of the standard VC features, such as the volume rendered endoluminal fly-through, measurement tool, bookmark modes, electronic biopsy, and slice views. The use of VR immersion, stereo, and wider field of view and field of regard has a positive effect on polyp search and analysis tasks in our immersive VC system, a volumetric-based immersive analytics application. Navigation includes enhanced automatic speed and direction controls, based on the user's head orientation, in conjunction with physical navigation for exploration of local proximity. In order to accommodate the resolution and frame rate requirements for HMDs, new rendering techniques have been developed, including mesh-assisted volume raycasting and a novel lighting paradigm. Feedback and further suggestions from expert radiologists show the promise of our system for immersive analysis for VC and encourage new avenues for exploring the use of VR in visualization systems for medical diagnosis.", "cite": 1, "year": "2019"}], "name": "Marino,Joseph", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "1", "target": "4"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "2", "target": "11"}, {"source": "2", "target": "10"}, {"source": "3", "target": "4"}, {"source": "3", "target": "11"}, {"source": "3", "target": "12"}, {"source": "3", "target": "13"}, {"source": "3", "target": "14"}, {"source": "3", "target": "10"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "5", "target": "6"}, {"source": "7", "target": "8"}, {"source": "7", "target": "9"}, {"source": "7", "target": "10"}, {"source": "8", "target": "9"}, {"source": "8", "target": "10"}, {"source": "9", "target": "10"}, {"source": "10", "target": "11"}, {"source": "10", "target": "12"}, {"source": "10", "target": "13"}, {"source": "10", "target": "14"}], "year": 2019, "authorId": {"0": "Marino,Joseph", "1": "Park,JiHwan", "2": "Nadeem,Saad", "3": "Boorboor,Saeed", "4": "Kaufman,ArieE", "5": "Dmitriev,Konstantin", "6": "Baker,Kevin", "7": "Mirhosseini,Seyedkoosha", "8": "Gutenko,Ievgeniia", "9": "Ojal,Sushant", "10": "Kaufman,Arie", "11": "Jadhav,Shreeraj", "12": "Ananth,Mala", "13": "Talmage,David", "14": "Role,Lorna"}}