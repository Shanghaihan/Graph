{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 1], [0, 4], [0, 3], [1, 5], [1, 6], [1, 4], [1, 0], [1, 2], [1, 3], [1, 4], [1, 0], [1, 4], [1, 3], [2, 1], [2, 0], [2, 3], [2, 4], [3, 1], [3, 0], [3, 2], [3, 4], [3, 1], [3, 0], [3, 4], [4, 1], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 1], [4, 0], [4, 2], [4, 3], [4, 13], [4, 14], [4, 15], [4, 16], [4, 1], [4, 0], [4, 3], [4, 5], [4, 17], [4, 18], [1, 5], [1, 6], [1, 4], [1, 0], [1, 2], [1, 3], [1, 4], [1, 0], [1, 4], [1, 3], [4, 1], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 1], [4, 0], [4, 2], [4, 3], [4, 13], [4, 14], [4, 15], [4, 16], [4, 1], [4, 0], [4, 3], [4, 5], [4, 17], [4, 18], [3, 1], [3, 0], [3, 2], [3, 4], [3, 1], [3, 0], [3, 4]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15", "16": "16", "17": "17", "18": "18"}, "count": 2, "cite": 22, "position": 2.0, "connect": 1.75, "totalConnect": 3.5, "totalCount": 0.42105263157894735, "totalCite": 5.5, "totalPosition": 5.125, "paper": [{"title": "DeepVID: Deep Visual Interpretation and Diagnosis for Image Classifiers via Knowledge Distillation", "author": ["Wang,Junpeng", "Gou,Liang", "Zhang,Wei", "Yang,Hao", "Shen,Han-Wei"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2019.2903943", "keywords": "", "abstract": "Deep Neural Networks (DNNs) have been extensively used in multiple disciplines due to their superior performance. However, in most cases, DNNs are considered as black-boxes and the interpretation of their internal working mechanism is usually challenging. Given that model trust is often built on the understanding of how a model works, the interpretation of DNNs becomes more important, especially in safety-critical applications (e.g., medical diagnosis, autonomous driving). In this paper, we propose DeepVID, a Deep learning approach to Visually Interpret and Diagnose DNN models, especially image classifiers. In detail, we train a small locally-faithful model to mimic the behavior of an original cumbersome DNN around a particular data instance of interest, and the local model is sufficiently simple such that it can be visually interpreted (e.g., a linear model). Knowledge distillation is used to transfer the knowledge from the cumbersome DNN to the small model, and a deep generative model (i.e., variational auto-encoder) is used to generate neighbors around the instance of interest. Those neighbors, which come with small feature variances and semantic meanings, can effectively probe the DNN's behaviors around the interested instance and help the small model to learn those behaviors. Through comprehensive evaluations, as well as case studies conducted together with deep learning experts, we validate the effectiveness of DeepVID.", "cite": 10, "year": "2019"}, {"title": "DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks", "author": ["Wang,Junpeng", "Gou,Liang", "Shen,Han-Wei", "Yang,Hao"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2864504", "keywords": "", "abstract": "Deep Q-Network (DON). as one type of deep reinforcement learning model. targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent's experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand. diagnose, and potentially improve DQN models.", "cite": 12, "year": "2019"}], "name": "Gou,Liang", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}, {"id": "16"}, {"id": "17"}, {"id": "18"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "1", "target": "5"}, {"source": "1", "target": "6"}, {"source": "1", "target": "4"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "3", "target": "4"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "4", "target": "7"}, {"source": "4", "target": "8"}, {"source": "4", "target": "9"}, {"source": "4", "target": "10"}, {"source": "4", "target": "11"}, {"source": "4", "target": "12"}, {"source": "4", "target": "13"}, {"source": "4", "target": "14"}, {"source": "4", "target": "15"}, {"source": "4", "target": "16"}, {"source": "4", "target": "17"}, {"source": "4", "target": "18"}], "year": 2019, "authorId": {"0": "Gou,Liang", "1": "Wang,Junpeng", "2": "Zhang,Wei", "3": "Yang,Hao", "4": "Shen,Han-Wei", "5": "Hazarika,Subhashis", "6": "Li,Cheng", "7": "Guo,Hanqi", "8": "He,Wenbin", "9": "Seo,Sangmin", "10": "Constantinescu,EmilMihai", "11": "Liu,Chunhui", "12": "Peterka,Tom", "13": "Ji,Xiaonan", "14": "Ritter,Alan", "15": "Machiraju,Raghu", "16": "Yen,Po-Yin", "17": "Dutta,Soumya", "18": "Chen,Jen-Ping"}}