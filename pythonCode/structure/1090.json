{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 1], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [1, 2], [1, 3], [1, 4], [1, 0], [1, 5], [1, 0], [2, 1], [2, 3], [2, 4], [2, 0], [3, 1], [3, 2], [3, 4], [3, 0], [4, 1], [4, 2], [4, 3], [4, 0], [1, 2], [1, 3], [1, 4], [1, 0], [1, 5], [1, 0], [5, 11], [5, 12], [5, 13], [5, 1], [5, 0], [6, 7], [6, 0], [7, 6], [7, 0], [8, 9], [8, 0], [8, 10], [9, 8], [9, 0], [9, 10], [10, 14], [10, 15], [10, 16], [10, 8], [10, 9], [10, 0]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15", "16": "16"}, "count": 4, "cite": 16, "position": 3.5, "connect": 1.1, "totalConnect": 2.074074074074074, "totalCount": 0.5882352941176471, "totalCite": 5.2, "totalPosition": 3.7, "paper": [{"title": "Vistrates: A Component Model for Ubiquitous Analytics", "author": ["Badam,SriramKarthik", "Mathisen,Andreas", "Radle,Roman", "Klokmose,ClemensN.", "Elmqvist,Niklas"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865144", "keywords": "", "abstract": "Visualization tools are often specialized for specific tasks, which turns the user's analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where components the building blocks of this model can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce VISTRATES, a literate computing platform for developing. assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective. Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic \"anytime\" and \"anywhere\" motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices.", "cite": 6, "year": "2019"}, {"title": "Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading", "author": ["Badam,SriramKarthik", "Liu,Zhicheng", "Elmqvist,Niklas"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865119", "keywords": "", "abstract": "Today's data-rich documents are often complex datasets in themselves, consisting of information in different formats such as text, figures, and data tables. These additional media augment the textual narrative in the document. However, the static layout of a traditional for-print document often impedes deep understanding of its content because of the need to navigate to access content scattered throughout the text. In this paper, we seek to facilitate enhanced comprehension of such documents through a contextual visualization technique that couples text content with data tables contained in the document. We parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document. We evaluate this technique in a user study comparing our approach to a traditional reading experience. Results from our study show that (1) participants comprehend the content better with tighter coupling of text and data, (2) the contextual visualizations enable participants to develop better summaries that capture the main data-rich insights within the document, and (3) overall, our method enables participants to develop a more detailed understanding of the document content.", "cite": 0, "year": "2019"}, {"title": "Information Olfactation: Harnessing Scent to Convey Data", "author": ["Patnaik,Biswaksen", "Batch,Andrea", "Elmqvist,Niklas"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865237", "keywords": "", "abstract": "Olfactory feedback for analytical tasks is a virtually unexplored area in spite of the advantages it offers for information recall, feature identification. and location detection. Here we introduce the concept of information olfactation as the fragrant sibling of information visualization. and discuss how scent can be used to convey data. Building on a review of the human olfactory system and mirroring common visualization practice. we propose olfactory marks, the substrate in which they exist. and their olfactory channels that are available to designers. To exemplify this idea, we present vlScENT: A six-scent stereo olfactory display capable of conveying olfactory glyphs of varying temperature and direction. as well as a corresponding software system that integrates the display with a traditional visualization display. Finally, we present three applications that make use of the viScent system: A 2D graph visualization, a 2D line and point chart. and an immersive analytics graph visualization in 3D virtual reality. We close the paper with a review of possible extensions of viScent and applications of information olfactation for general visualization beyond the examples in this paper.", "cite": 3, "year": "2019"}, {"title": "Face to Face: Evaluating Visual Comparison", "author": ["Ondov,Brian", "Jardine,Nicole", "Elmqvist,Niklas", "Franconeri,Steven"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2864884", "keywords": "", "abstract": "Data are often viewed as a single set of values, but those values frequently must be compared with another set. The existing evaluations of designs that facilitate these comparisons tend to be based on intuitive reasoning, rather than quantifiable measures. We build on this work with a series of crowdsourced experiments that use low-level perceptual comparison tasks that arise frequently in comparisons within data visualizations (e.g., which value changes the most between the two sets of data?). Participants completed these tasks across a variety of layouts: overlaid, two arrangements of juxtaposed small multiples, mirror-symmetric small multiples, and animated transitions. A staircase procedure sought the difficulty level (e.g., value change delta) that led to equivalent accuracy for each layout. Confirming prior intuition, we observe high levels of performance for overlaid versus standard small multiples. However, we also find performance improvements for both mirror symmetric small multiples and animated transitions. While some results are incongruent with common wisdom in data visualization, they align with previous work in perceptual psychology, and thus have potentially strong implications for visual comparison designs.", "cite": 7, "year": "2019"}], "name": "Elmqvist,Niklas", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}, {"id": "16"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "1", "target": "4"}, {"source": "1", "target": "5"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "3", "target": "4"}, {"source": "5", "target": "11"}, {"source": "5", "target": "12"}, {"source": "5", "target": "13"}, {"source": "6", "target": "7"}, {"source": "8", "target": "9"}, {"source": "8", "target": "10"}, {"source": "9", "target": "10"}, {"source": "10", "target": "14"}, {"source": "10", "target": "15"}, {"source": "10", "target": "16"}], "year": 2019, "authorId": {"0": "Elmqvist,Niklas", "1": "Badam,SriramKarthik", "2": "Mathisen,Andreas", "3": "Radle,Roman", "4": "Klokmose,ClemensN.", "5": "Liu,Zhicheng", "6": "Patnaik,Biswaksen", "7": "Batch,Andrea", "8": "Ondov,Brian", "9": "Jardine,Nicole", "10": "Franconeri,Steven", "11": "Law,Po-Ming", "12": "Malik,Sana", "13": "Basole,RahulC.", "14": "Dimara,Evanthia", "15": "Bailly,Gilles", "16": "Bezerianos,Anastasia"}}