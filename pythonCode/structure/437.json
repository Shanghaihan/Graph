{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [1, 0], [1, 2], [1, 3], [2, 1], [2, 0], [2, 3], [3, 1], [3, 0], [3, 2], [4, 0], [4, 5], [4, 6], [4, 7], [5, 0], [5, 4], [5, 6], [5, 7], [6, 0], [6, 4], [6, 5], [6, 7], [7, 0], [7, 4], [7, 5], [7, 6]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7"}, "count": 2, "cite": 32, "position": 1.5, "connect": 1.0, "totalConnect": 2.0, "totalCount": 0.25, "totalCite": 16.0, "totalPosition": 4.5, "paper": [{"title": "Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers", "author": ["Hohman,Fred", "Kahng,Minsuk", "Pienta,Robert", "Chau,DuenHorng"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2843369", "keywords": "", "abstract": "Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.", "cite": 20, "year": "2019"}, {"title": "GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation", "author": ["Kahng,Minsuk", "Thorat,Nikhil", "Chau,DuenHorng(Polo)", "Viegas,FernandaB.", "Wattenberg,Martin"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2864500", "keywords": "", "abstract": "Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process's intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN's structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning.", "cite": 12, "year": "2019"}], "name": "Kahng,Minsuk", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "2", "target": "3"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "4", "target": "7"}, {"source": "5", "target": "6"}, {"source": "5", "target": "7"}, {"source": "6", "target": "7"}], "year": 2019, "authorId": {"0": "Kahng,Minsuk", "1": "Hohman,Fred", "2": "Pienta,Robert", "3": "Chau,DuenHorng", "4": "Thorat,Nikhil", "5": "Chau,DuenHorng(Polo)", "6": "Viegas,FernandaB.", "7": "Wattenberg,Martin"}}