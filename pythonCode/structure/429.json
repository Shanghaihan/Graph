{"edges": [[0, 1], [0, 2], [1, 0], [1, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 1], [2, 0], [2, 8], [2, 3], [2, 9]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9"}, "count": 1, "cite": 1, "position": 2.0, "connect": 1.0, "totalConnect": 1.4, "totalCount": 0.7, "totalCite": 1.2857142857142858, "totalPosition": 4.857142857142857, "paper": [{"title": "Realtime and Accurate 3D Eye Gaze Capture with DCNN-based Iris and Pupil Segmentation.", "author": ["Wang,Zhiyong", "Chai,Jinxiang", "Xia,Shihong"], "soname": "IEEE transactions on visualization and computer graphics", "DOI": "10.1109/TVCG.2019.2938165", "keywords": "", "abstract": "This paper presents a realtime and accurate method for 3D eye gaze tracking with a monocular RGB camera. Our key idea is to train a deep convolutional neural network(DCNN) that automatically extracts the iris and pupil pixels of each eye from input images. To achieve this goal, we combine the power of Unet\\cite{ronneberger2015u-net:} and Squeezenet\\cite{iandola2017squeezenet:} to train an efficient convolutional neural network for pixel classification. In addition, we track the 3D eye gaze state in the Maximum A Posteriori (MAP) framework, which sequentially searches for the most likely state of the 3D eye gaze at each frame. When eye blinking occurs, the eye gaze tracker can obtain an inaccurate result. We further extend the convolutional neural network for eye close detection in order to improve the robustness and accuracy of the eye gaze tracker. Our system runs in realtime on desktop PCs and smart phones. We have evaluated our system on live videos and Internet videos, and our results demonstrate that the system is robust and accurate for various genders, races, lighting conditions, poses, shapes and facial expressions. A comparison against Wang et al.[3] shows that our method advances the state of the art in 3D eye tracking using a single RGB camera.", "cite": 1, "year": "2019"}], "name": "Chai,Jinxiang", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "1", "target": "2"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "2", "target": "5"}, {"source": "2", "target": "6"}, {"source": "2", "target": "7"}, {"source": "2", "target": "8"}, {"source": "2", "target": "9"}], "year": 2019, "authorId": {"0": "Chai,Jinxiang", "1": "Wang,Zhiyong", "2": "Xia,Shihong", "3": "Gao,Lin", "4": "Lai,Yu-Kun", "5": "Yang,Jie", "6": "Ling-Xiao,Zhang", "7": "Kobbelt,Leif", "8": "Yuan,Ming-Ze", "9": "Fu,Hongbo"}}