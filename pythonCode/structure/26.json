{"edges": [[0, 1], [0, 2], [1, 0], [1, 2], [2, 1], [2, 0]], "features": {"0": "0", "1": "1", "2": "2"}, "count": 1, "cite": 0, "position": 2.0, "connect": 1.0, "totalConnect": 2.0, "totalCount": 0.3333333333333333, "totalCite": 0.0, "totalPosition": 3.0, "paper": [{"title": "Planar Abstraction and Inverse Rendering of 3D Indoor Environment.", "author": ["Kim,YoungMin", "Ryu,Sangwoo", "Kim,Ig-Jae"], "soname": "IEEE transactions on visualization and computer graphics", "DOI": "10.1109/TVCG.2019.2960776", "keywords": "", "abstract": "Scanning and acquiring a 3D indoor environment suffers from complex occlusions and misalignment errors. The reconstruction obtained from an RGB-D scanner contains holes in geometry and ghosting in texture. These are easily noticeable and cannot be considered as visually compelling VR content without further processing. On the other hand, the well-known Manhattan World priors successfully recreate relatively simple structures. In this paper, we would like to push the limit of planar representation in indoor environments. Given an initial 3D reconstruction captured by an RGB-D sensor, we use planes not only to represent the environment geometrically but also to solve an inverse rendering problem considering texture and light. The complex process of shape inference and intrinsic imaging is greatly simplified with the help of detected planes and yet produces a realistic 3D indoor environment. The generated content can adequately represent the spatial arrangements for various AR/VR applications and can be readily composited with virtual objects possessing plausible lighting and texture.", "cite": 0, "year": "2019"}], "name": "Ryu,Sangwoo", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "1", "target": "2"}], "year": 2019, "authorId": {"0": "Ryu,Sangwoo", "1": "Kim,YoungMin", "2": "Kim,Ig-Jae"}}