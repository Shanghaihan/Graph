{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 1], [0, 3], [0, 6], [0, 7], [0, 5], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [1, 2], [1, 3], [1, 4], [1, 5], [1, 0], [1, 3], [1, 6], [1, 7], [1, 0], [1, 5], [2, 1], [2, 3], [2, 4], [2, 5], [2, 0], [3, 1], [3, 2], [3, 4], [3, 5], [3, 0], [3, 1], [3, 6], [3, 7], [3, 0], [3, 5], [3, 14], [3, 15], [3, 16], [4, 1], [4, 2], [4, 3], [4, 5], [4, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 0], [5, 1], [5, 3], [5, 6], [5, 7], [5, 0], [1, 2], [1, 3], [1, 4], [1, 5], [1, 0], [1, 3], [1, 6], [1, 7], [1, 0], [1, 5], [3, 1], [3, 2], [3, 4], [3, 5], [3, 0], [3, 1], [3, 6], [3, 7], [3, 0], [3, 5], [3, 14], [3, 15], [3, 16], [6, 1], [6, 3], [6, 7], [6, 0], [6, 5], [6, 17], [6, 18], [7, 1], [7, 3], [7, 6], [7, 0], [7, 5], [5, 1], [5, 2], [5, 3], [5, 4], [5, 0], [5, 1], [5, 3], [5, 6], [5, 7], [5, 0], [8, 0], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [9, 8], [9, 0], [9, 10], [9, 11], [9, 12], [9, 13], [10, 8], [10, 0], [10, 9], [10, 11], [10, 12], [10, 13], [11, 8], [11, 0], [11, 9], [11, 10], [11, 12], [11, 13], [12, 8], [12, 0], [12, 9], [12, 10], [12, 11], [12, 13], [13, 8], [13, 0], [13, 9], [13, 10], [13, 11], [13, 12]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15", "16": "16", "17": "17", "18": "18"}, "count": 3, "cite": 1, "position": 4.333333333333333, "connect": 1.2307692307692308, "totalConnect": 2.8, "totalCount": 0.3684210526315789, "totalCite": 3.142857142857143, "totalPosition": 5.0, "paper": [{"title": "Global Beautification of 2D and 3D Layouts with Interactive Ambiguity Resolution.", "author": ["Xu,Pengfei", "Yan,Guohang", "Fu,Hongbo", "Igarashi,Takeo", "Tai,Chiew-Lan", "Huang,Hui"], "soname": "IEEE transactions on visualization and computer graphics", "DOI": "10.1109/TVCG.2019.2954321", "keywords": "", "abstract": "Specifying precise relationships among graphic elements is often a time-consuming process with traditional alignment tools. Automatic beautification of roughly designed layouts can provide a more efficient solution but often lead to undesired results due to ambiguity problems. To facilitate ambiguity resolution in layout beautification, we present a novel user interface for visualizing and editing inferred relationships through an automatic global layout beautification process. First, our interface provides a preview of the beautified layout with inferred constraints without directly modifying an input layout. In this way, the user can easily keep refining beautification results by interactively repositioning and/or resizing elements in the input layout. Second, we present a gestural interface for editing automatically inferred constraints by directly interacting with the visualized constraints via simple gestures. Our technique is applicable to both 2D and 3D global layout beautification, supported by efficient system implementation that provides instant user feedback. Our user study validates that our tool is capable of creating, editing and refining layouts of graphic elements, and is significantly faster than the standard snap-dragging or command-based alignment tools for both 2D and 3D layout tasks.", "cite": 0, "year": "2019"}, {"title": "Model-Guided 3D Sketching", "author": ["Xu,Pengfei", "Fu,Hongbo", "Zheng,Youyi", "Singh,Karan", "Huang,Hui", "Tai,Chiew-Lan"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2860016", "keywords": "", "abstract": "We present a novel 3D model-guided interface for in-situ sketching on 3D planes. Our work is motivated by evolutionary design, where existing 3D objects form the basis for conceptual re-design or further design exploration. We contribute a novel workflow that exploits the geometry of an underlying 3D model to infer 3D planes on which 2D strokes drawn that are on and around the 3D model should be meaningfully projected. This provides users with the nearly modeless fluidity of a sketching interface, and is particularly useful for 3D sketching over planes that are not easily accessible or do not preexist. We also provide an additional set of tools, including sketching with explicit plane selection and model-aware canvas manipulation. Our system is evaluated with a user study, showing that our technique is easy to learn and effective for rapid sketching of product design variations around existing 3D models.", "cite": 0, "year": "2019"}, {"title": "A Sampling Approach to Generating Closely Interacting 3D Pose-Pairs from 2D Annotations", "author": ["Yin,Kangxue", "Huang,Hui", "Ho,EdmondS.L.", "Wang,Hao", "Komura,Taku", "Cohen-Or,Daniel", "Zhang,Hao"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2832097", "keywords": "", "abstract": "We introduce a data-driven method to generate a large number of plausible, closely interacting 3D human pose-pairs, for a given motion category, e.g., wrestling or salsa dance. With much difficulty in acquiring close interactions using 3D sensors, our approach utilizes abundant existing video data which cover many human activities. Instead of treating the data generation problem as one of reconstruction, either through 3D acquisition or direct 2D-to-3D data lifting from video annotations, we present a solution based on Markov Chain Monte Carlo (MCMC) sampling. Given a motion category and a set of video frames depicting the motion with the 2D pose-pair in each frame annotated, we start the sampling with one or few seed 3D pose-pairs which are manually created based on the target motion category. The initial set is then augmented by MCMC sampling around the seeds, via the Metropolis-Hastings algorithm and guided by a probability density function (PDF) that is defined by two terms to bias the sampling towards 3D pose-pairs that are physically valid and plausible for the motion category. With a focus on efficient sampling over the space of close interactions, rather than pose spaces, we develop a novel representation called interaction coordinates (IC) to encode both poses and their interactions in an integrated manner. Plausibility of a 3D pose-pair is then defined based on the IC and with respect to the annotated 2D pose-pairs from video. We show that our sampling-based approach is able to efficiently synthesize a large volume of plausible, closely interacting 3D pose-pairs which provide a good coverage of the input 2D pose-pairs.", "cite": 1, "year": "2019"}], "name": "Huang,Hui", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}, {"id": "16"}, {"id": "17"}, {"id": "18"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "0", "target": "11"}, {"source": "0", "target": "12"}, {"source": "0", "target": "13"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "1", "target": "4"}, {"source": "1", "target": "5"}, {"source": "1", "target": "6"}, {"source": "1", "target": "7"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "2", "target": "5"}, {"source": "3", "target": "4"}, {"source": "3", "target": "5"}, {"source": "3", "target": "6"}, {"source": "3", "target": "7"}, {"source": "3", "target": "14"}, {"source": "3", "target": "15"}, {"source": "3", "target": "16"}, {"source": "4", "target": "5"}, {"source": "5", "target": "6"}, {"source": "5", "target": "7"}, {"source": "6", "target": "7"}, {"source": "6", "target": "17"}, {"source": "6", "target": "18"}, {"source": "8", "target": "9"}, {"source": "8", "target": "10"}, {"source": "8", "target": "11"}, {"source": "8", "target": "12"}, {"source": "8", "target": "13"}, {"source": "9", "target": "10"}, {"source": "9", "target": "11"}, {"source": "9", "target": "12"}, {"source": "9", "target": "13"}, {"source": "10", "target": "11"}, {"source": "10", "target": "12"}, {"source": "10", "target": "13"}, {"source": "11", "target": "12"}, {"source": "11", "target": "13"}, {"source": "12", "target": "13"}], "year": 2019, "authorId": {"0": "Huang,Hui", "1": "Xu,Pengfei", "2": "Yan,Guohang", "3": "Fu,Hongbo", "4": "Igarashi,Takeo", "5": "Tai,Chiew-Lan", "6": "Zheng,Youyi", "7": "Singh,Karan", "8": "Yin,Kangxue", "9": "Ho,EdmondS.L.", "10": "Wang,Hao", "11": "Komura,Taku", "12": "Cohen-Or,Daniel", "13": "Zhang,Hao", "14": "Yuan,Ming-Ze", "15": "Gao,Lin", "16": "Xia,Shihong", "17": "Xu,Xiaojie", "18": "Liu,Chang"}}