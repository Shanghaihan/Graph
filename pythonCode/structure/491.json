{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [1, 2], [1, 3], [1, 0], [1, 4], [1, 4], [1, 14], [1, 15], [1, 16], [1, 17], [1, 18], [1, 19], [2, 1], [2, 3], [2, 0], [2, 4], [3, 1], [3, 2], [3, 0], [3, 4], [4, 1], [4, 2], [4, 3], [4, 0], [4, 1], [4, 14], [4, 15], [4, 16], [4, 17], [4, 18], [4, 19], [4, 20], [4, 21], [4, 22], [4, 23], [4, 24], [4, 25], [4, 26], [4, 27], [4, 28], [4, 29], [5, 6], [5, 7], [5, 8], [5, 0], [6, 5], [6, 7], [6, 8], [6, 0], [7, 5], [7, 6], [7, 8], [7, 0], [8, 5], [8, 6], [8, 7], [8, 0], [8, 30], [8, 31], [8, 32], [8, 33], [8, 34], [9, 10], [9, 11], [9, 12], [9, 13], [9, 0], [10, 9], [10, 11], [10, 12], [10, 13], [10, 0], [11, 9], [11, 10], [11, 12], [11, 13], [11, 0], [12, 9], [12, 10], [12, 11], [12, 13], [12, 0], [13, 9], [13, 10], [13, 11], [13, 12], [13, 0]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15", "16": "16", "17": "17", "18": "18", "19": "19", "20": "20", "21": "21", "22": "22", "23": "23", "24": "24", "25": "25", "26": "26", "27": "27", "28": "28", "29": "29", "30": "30", "31": "31", "32": "32", "33": "33", "34": "34"}, "count": 3, "cite": 17, "position": 5.0, "connect": 1.0, "totalConnect": 1.596774193548387, "totalCount": 0.45714285714285713, "totalCite": 6.8125, "totalPosition": 6.1875, "paper": [{"title": "A Semantic-Based Method for Visualizing Large Image Collections", "author": ["Xie,Xiao", "Cai,Xiwen", "Zhou,Junpei", "Cao,Nan", "Wu,Yingcai"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2835485", "keywords": "", "abstract": "Interactive visualization of large image collections is important and useful in many applications, such as personal album management and user profiling on images. However, most prior studies focus on using low-level visual features of images, such as texture and color histogram, to create visualizations without considering the more important semantic information embedded in images. This paper proposes a novel visual analytic system to analyze images in a semantic-aware manner. The system mainly comprises two components: a semantic information extractor and a visual layout generator. The semantic information extractor employs an image captioning technique based on convolutional neural network (CNN) to produce descriptive captions for images, which can be transformed into semantic keywords. The layout generator employs a novel co-embedding model to project images and the associated semantic keywords to the same 2D space. Inspired by the galaxy metaphor, we further turn the projected 2D space to a galaxy visualization of images, in which semantic keywords and images are visually encoded as stars and planets. Our system naturally supports multi-scale visualization and navigation, in which users can immediately see a semantic overview of an image collection and drill down for detailed inspection of a certain group of images. Users can iteratively refine the visual layout by integrating their domain knowledge into the co-embedding process. Two task-based evaluations are conducted to demonstrate the effectiveness of our system.", "cite": 5, "year": "2019"}, {"title": "EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data", "author": ["Xu,Ke", "Xia,Meng", "Mu,Xing", "Wang,Yun", "Cao,Nan"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2864825", "keywords": "", "abstract": "The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.", "cite": 6, "year": "2019"}, {"title": "Visual Progression Analysis of Event Sequence Data", "author": ["Guo,Shunan", "Jin,Zhuochen", "Gotz,David", "Du,Fan", "Zha,Hongyuan", "Cao,Nan"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2864885", "keywords": "", "abstract": "Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identification and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a significant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help define those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET2, which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET2: (1) case studies with two real -world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design.", "cite": 6, "year": "2019"}], "name": "Cao,Nan", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}, {"id": "16"}, {"id": "17"}, {"id": "18"}, {"id": "19"}, {"id": "20"}, {"id": "21"}, {"id": "22"}, {"id": "23"}, {"id": "24"}, {"id": "25"}, {"id": "26"}, {"id": "27"}, {"id": "28"}, {"id": "29"}, {"id": "30"}, {"id": "31"}, {"id": "32"}, {"id": "33"}, {"id": "34"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "0", "target": "11"}, {"source": "0", "target": "12"}, {"source": "0", "target": "13"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "1", "target": "4"}, {"source": "1", "target": "14"}, {"source": "1", "target": "15"}, {"source": "1", "target": "16"}, {"source": "1", "target": "17"}, {"source": "1", "target": "18"}, {"source": "1", "target": "19"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "3", "target": "4"}, {"source": "4", "target": "14"}, {"source": "4", "target": "15"}, {"source": "4", "target": "16"}, {"source": "4", "target": "17"}, {"source": "4", "target": "18"}, {"source": "4", "target": "19"}, {"source": "4", "target": "20"}, {"source": "4", "target": "21"}, {"source": "4", "target": "22"}, {"source": "4", "target": "23"}, {"source": "4", "target": "24"}, {"source": "4", "target": "25"}, {"source": "4", "target": "26"}, {"source": "4", "target": "27"}, {"source": "4", "target": "28"}, {"source": "4", "target": "29"}, {"source": "5", "target": "6"}, {"source": "5", "target": "7"}, {"source": "5", "target": "8"}, {"source": "6", "target": "7"}, {"source": "6", "target": "8"}, {"source": "7", "target": "8"}, {"source": "8", "target": "30"}, {"source": "8", "target": "31"}, {"source": "8", "target": "32"}, {"source": "8", "target": "33"}, {"source": "8", "target": "34"}, {"source": "9", "target": "10"}, {"source": "9", "target": "11"}, {"source": "9", "target": "12"}, {"source": "9", "target": "13"}, {"source": "10", "target": "11"}, {"source": "10", "target": "12"}, {"source": "10", "target": "13"}, {"source": "11", "target": "12"}, {"source": "11", "target": "13"}, {"source": "12", "target": "13"}], "year": 2019, "authorId": {"0": "Cao,Nan", "1": "Xie,Xiao", "2": "Cai,Xiwen", "3": "Zhou,Junpei", "4": "Wu,Yingcai", "5": "Xu,Ke", "6": "Xia,Meng", "7": "Mu,Xing", "8": "Wang,Yun", "9": "Guo,Shunan", "10": "Jin,Zhuochen", "11": "Gotz,David", "12": "Du,Fan", "13": "Zha,Hongyuan", "14": "Wang,Jiachen", "15": "Deng,Dazhen", "16": "Liang,Hongye", "17": "Zhang,Hui", "18": "Cheng,Shoubin", "19": "Chen,Wei", "20": "Weng,Di", "21": "Chen,Ran", "22": "Deng,Zikun", "23": "Wu,Feiran", "24": "Chen,Jingmin", "25": "Tang,Tan", "26": "Rubab,Sadia", "27": "Lai,Jiewen", "28": "Cui,Weiwei", "29": "Yu,Lingyun", "30": "Lu,Zhicong", "31": "Fan,Mingming", "32": "Zhao,Jian", "33": "Annett,Michelle", "34": "Wigdor,Daniel"}}