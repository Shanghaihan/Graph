{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 1], [0, 8], [0, 9], [0, 10], [1, 2], [1, 0], [1, 7], [1, 8], [1, 9], [1, 10], [1, 0], [2, 11], [2, 7], [2, 6], [2, 12], [2, 1], [2, 0], [3, 4], [3, 5], [3, 6], [3, 0], [4, 3], [4, 5], [4, 6], [4, 0], [5, 3], [5, 4], [5, 6], [5, 0], [6, 11], [6, 2], [6, 7], [6, 12], [6, 13], [6, 14], [6, 12], [6, 3], [6, 4], [6, 5], [6, 0], [7, 11], [7, 2], [7, 6], [7, 12], [7, 1], [7, 8], [7, 9], [7, 10], [7, 0], [1, 2], [1, 0], [1, 7], [1, 8], [1, 9], [1, 10], [1, 0], [8, 7], [8, 1], [8, 9], [8, 10], [8, 0], [9, 7], [9, 1], [9, 8], [9, 10], [9, 0], [10, 7], [10, 1], [10, 8], [10, 9], [10, 0]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14"}, "count": 3, "cite": 5, "position": 4.666666666666667, "connect": 1.1, "totalConnect": 2.0526315789473686, "totalCount": 0.3333333333333333, "totalCite": 1.0, "totalPosition": 4.6, "paper": [{"title": "FeatureLego: Volume Exploration Using Exhaustive Clustering of Super-Voxels", "author": ["Jadhav,Shreeraj", "Nadeem,Saad", "Kaufman,Arie"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2856744", "keywords": "", "abstract": "We present a volume exploration framework, FeatureLego, that uses a novel voxel clustering approach for efficient selection of semantic features. We partition the input volume into a set of compact super-voxels that represent the finest selection granularity. We then performan exhaustive clustering of these super-voxels using a graph-based clustering method. Unlike the prevalent brute-force parameter sampling approaches, we propose an efficient algorithm to performthis exhaustive clustering. By computing an exhaustive set of clusters, we aim to capture as many boundaries as possible and ensure that the user has sufficient options for efficiently selecting semantically relevant features. Furthermore, we merge all the computed clusters into a single tree of meta-clusters that can be used for hierarchical exploration. We implement an intuitive user-interface to interactively explore volumes using our clustering approach. Finally, we show the effectiveness of our framework on multiple real-world datasets of different modalities.", "cite": 0, "year": "2019"}, {"title": "Immersive Virtual Colonoscopy", "author": ["Mirhosseini,Seyedkoosha", "Gutenko,Ievgeniia", "Ojal,Sushant", "Marino,Joseph", "Kaufman,Arie"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2019.2898763", "keywords": "", "abstract": "Virtual colonoscopy (VC) is a non-invasive screening tool for colorectal polyps which employs volume visualization of a colon model reconstructed from a CT scan of the patient's abdomen. We present an immersive analytics system for VC which enhances and improves the traditional desktop VC through the use of VR technologies. Our system, using a head-mounted display (HMD), includes all of the standard VC features, such as the volume rendered endoluminal fly-through, measurement tool, bookmark modes, electronic biopsy, and slice views. The use of VR immersion, stereo, and wider field of view and field of regard has a positive effect on polyp search and analysis tasks in our immersive VC system, a volumetric-based immersive analytics application. Navigation includes enhanced automatic speed and direction controls, based on the user's head orientation, in conjunction with physical navigation for exploration of local proximity. In order to accommodate the resolution and frame rate requirements for HMDs, new rendering techniques have been developed, including mesh-assisted volume raycasting and a novel lighting paradigm. Feedback and further suggestions from expert radiologists show the promise of our system for immersive analysis for VC and encourage new avenues for exploring the use of VR in visualization systems for medical diagnosis.", "cite": 1, "year": "2019"}, {"title": "Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images", "author": ["Boorboor,Saeed", "Jadhav,Shreeraj", "Ananth,Mala", "Talmage,David", "Role,Lorna", "Kaufman,Arie"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2864852", "keywords": "", "abstract": "Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.", "cite": 4, "year": "2019"}], "name": "Kaufman,Arie", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "1", "target": "2"}, {"source": "1", "target": "7"}, {"source": "1", "target": "8"}, {"source": "1", "target": "9"}, {"source": "1", "target": "10"}, {"source": "2", "target": "11"}, {"source": "2", "target": "7"}, {"source": "2", "target": "6"}, {"source": "2", "target": "12"}, {"source": "3", "target": "4"}, {"source": "3", "target": "5"}, {"source": "3", "target": "6"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "5", "target": "6"}, {"source": "6", "target": "11"}, {"source": "6", "target": "7"}, {"source": "6", "target": "12"}, {"source": "6", "target": "13"}, {"source": "6", "target": "14"}, {"source": "7", "target": "11"}, {"source": "7", "target": "12"}, {"source": "7", "target": "8"}, {"source": "7", "target": "9"}, {"source": "7", "target": "10"}, {"source": "8", "target": "9"}, {"source": "8", "target": "10"}, {"source": "9", "target": "10"}], "year": 2019, "authorId": {"0": "Kaufman,Arie", "1": "Jadhav,Shreeraj", "2": "Nadeem,Saad", "3": "Mirhosseini,Seyedkoosha", "4": "Gutenko,Ievgeniia", "5": "Ojal,Sushant", "6": "Marino,Joseph", "7": "Boorboor,Saeed", "8": "Ananth,Mala", "9": "Talmage,David", "10": "Role,Lorna", "11": "Park,JiHwan", "12": "Kaufman,ArieE", "13": "Dmitriev,Konstantin", "14": "Baker,Kevin"}}