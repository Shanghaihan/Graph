{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [1, 2], [1, 3], [1, 4], [1, 5], [1, 0], [1, 6], [2, 1], [2, 3], [2, 4], [2, 5], [2, 0], [2, 6], [3, 1], [3, 2], [3, 4], [3, 5], [3, 0], [3, 6], [4, 1], [4, 2], [4, 3], [4, 5], [4, 0], [4, 6], [5, 1], [5, 2], [5, 3], [5, 4], [5, 0], [5, 6], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 0]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6"}, "count": 1, "cite": 0, "position": 6.0, "connect": 1.0, "totalConnect": 2.0, "totalCount": 0.14285714285714285, "totalCite": 0.0, "totalPosition": 7.0, "paper": [{"title": "Refocusable Gigapixel Panoramas for Immersive VR Experiences.", "author": ["Lyu,Wentao", "Ding,Peng", "Zhang,Yingliang", "Chen,Anpei", "Wu,Minye", "Yin,Shu", "Yu,Jingyi"], "soname": "IEEE transactions on visualization and computer graphics", "DOI": "10.1109/TVCG.2019.2940444", "keywords": "", "abstract": "There have been significant advances in capturing gigapixel panoramas (GPP). However, solutions for viewing GPPs on head-mounted displays (HMDs) are lagging: an immersive experience requires ultra-fast rendering while directly loading a GPP onto the GPU is infeasible due to limited texture memory capacity. In this paper, we present a novel out-of-core rendering technique that supports not only classic panning, tilting, and zooming but also dynamic refocusing for viewing a GPP on HMD. Inspired by the network package transmission mechanisms in distributed visualization, our approach employs hierarchical image tiling and on-demand data updates across the main and the GPU memory. We further present a multi-resolution rendering scheme and a refocused light field rendering technique based on RGBD GPPs with minimal memory overhead. Comprehensive experiments demonstrate that our technique is highly efficient and reliable, able to achieve ultra-high frame rates (> 50 fps) even on low-end GPUs. With an embedded gaze tracker, our technique enables immersive panorama viewing experiences with unprecedented resolutions, field-of-view, and focus variations while maintaining smooth spatial, angular, and focal transitions.", "cite": 0, "year": "2019"}], "name": "Yin,Shu", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "1", "target": "4"}, {"source": "1", "target": "5"}, {"source": "1", "target": "6"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "2", "target": "5"}, {"source": "2", "target": "6"}, {"source": "3", "target": "4"}, {"source": "3", "target": "5"}, {"source": "3", "target": "6"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "5", "target": "6"}], "year": 2019, "authorId": {"0": "Yin,Shu", "1": "Lyu,Wentao", "2": "Ding,Peng", "3": "Zhang,Yingliang", "4": "Chen,Anpei", "5": "Wu,Minye", "6": "Yu,Jingyi"}}