{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [0, 14], [0, 15], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 0], [1, 9], [2, 1], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 0], [2, 9], [3, 1], [3, 2], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 0], [3, 9], [4, 1], [4, 2], [4, 3], [4, 5], [4, 6], [4, 7], [4, 8], [4, 0], [4, 9], [5, 1], [5, 2], [5, 3], [5, 4], [5, 6], [5, 7], [5, 8], [5, 0], [5, 9], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 7], [6, 8], [6, 0], [6, 9], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 8], [7, 0], [7, 9], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 0], [8, 9], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 0], [10, 11], [10, 12], [10, 13], [10, 14], [10, 0], [10, 15], [11, 10], [11, 12], [11, 13], [11, 14], [11, 0], [11, 15], [12, 10], [12, 11], [12, 13], [12, 14], [12, 0], [12, 15], [13, 10], [13, 11], [13, 12], [13, 14], [13, 0], [13, 15], [14, 10], [14, 11], [14, 12], [14, 13], [14, 0], [14, 15], [15, 10], [15, 11], [15, 12], [15, 13], [15, 14], [15, 0]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15"}, "count": 2, "cite": 6, "position": 7.5, "connect": 1.0, "totalConnect": 2.0, "totalCount": 0.125, "totalCite": 3.0, "totalPosition": 8.5, "paper": [{"title": "A Perception-driven Hybrid Decomposition for Multi-layer Accommodative Displays", "author": ["Yu,Hyeonseung", "Bemana,Mojtaba", "Wernikowski,Marek", "Chwesiuk,Michal", "Tursun,OkanTarhan", "Singh,Gurprit", "Myszkowski,Karol", "Mantiuk,Radoslaw", "Seidel,Hans-Peter", "Didyk,Piotr"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2019.2898821", "keywords": "", "abstract": "Multi-focal plane and multi-layered light-field displays are promising solutions for addressing all visual cues observed in the real world. Unfortunately, these devices usually require expensive optimizations to compute a suitable decomposition of the input light field or focal stack to drive individual display layers. Although these methods provide near-correct image reconstruction, a significant computational cost prevents real-time applications. A simple alternative is a linear blending strategy which decomposes a single 2D image using depth information. This method provides real-time performance, but it generates inaccurate results at occlusion boundaries and on glossy surfaces. This paper proposes a perception-based hybrid decomposition technique which combines the advantages of the above strategies and achieves both real-time performance and high-fidelity results. The fundamental idea is to apply expensive optimizations only in regions where it is perceptually superior, e.g., depth discontinuities at the fovea, and fall back to less costly linear blending otherwise. We present a complete, perception-informed analysis and model that locally determine which of the two strategies should be applied. The prediction is later utilized by our new synthesis method which performs the image decomposition. The results are analyzed and validated in user experiments on a custom multi-plane display.", "cite": 3, "year": "2019"}, {"title": "Mo(2)Cap(2): Real-time Mobile 3D Motion Capture with a Cap-mounted Fisheye Camera", "author": ["Xu,Weipeng", "Chatterjee,Avishek", "Zollhofer,Michael", "Rhodin,Helge", "Fua,Pascal", "Seidel,Hans-Peter", "Theobalt,Christian"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2019.2898650", "keywords": "", "abstract": "We propose the first real-time system for the egocentric estimation of 3D human body pose in a wide range of unconstrained everyday activities. This setting has a unique set of challenges, such as mobility of the hardware setup, and robustness to long capture sessions with fast recovery from tracking failures. We tackle these challenges based on a novel lightweight setup that converts a standard baseball cap to a device for high-quality pose estimation based on a single cap-mounted fisheye camera. From the captured egocentric live stream, our CNN based 3D pose estimation approach runs at 60 Hz on a consumer-level GPU. In addition to the lightweight hardware setup, our other main contributions are: 1) a large ground truth training corpus of top-down fisheye images and 2) a disentangled 3D pose estimation approach that takes the unique properties of the egocentric viewpoint into account. As shown by our evaluation, we achieve lower 3D joint error as well as better 2D overlay than the existing baselines.", "cite": 3, "year": "2019"}], "name": "Seidel,Hans-Peter", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "0", "target": "11"}, {"source": "0", "target": "12"}, {"source": "0", "target": "13"}, {"source": "0", "target": "14"}, {"source": "0", "target": "15"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "1", "target": "4"}, {"source": "1", "target": "5"}, {"source": "1", "target": "6"}, {"source": "1", "target": "7"}, {"source": "1", "target": "8"}, {"source": "1", "target": "9"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "2", "target": "5"}, {"source": "2", "target": "6"}, {"source": "2", "target": "7"}, {"source": "2", "target": "8"}, {"source": "2", "target": "9"}, {"source": "3", "target": "4"}, {"source": "3", "target": "5"}, {"source": "3", "target": "6"}, {"source": "3", "target": "7"}, {"source": "3", "target": "8"}, {"source": "3", "target": "9"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "4", "target": "7"}, {"source": "4", "target": "8"}, {"source": "4", "target": "9"}, {"source": "5", "target": "6"}, {"source": "5", "target": "7"}, {"source": "5", "target": "8"}, {"source": "5", "target": "9"}, {"source": "6", "target": "7"}, {"source": "6", "target": "8"}, {"source": "6", "target": "9"}, {"source": "7", "target": "8"}, {"source": "7", "target": "9"}, {"source": "8", "target": "9"}, {"source": "10", "target": "11"}, {"source": "10", "target": "12"}, {"source": "10", "target": "13"}, {"source": "10", "target": "14"}, {"source": "10", "target": "15"}, {"source": "11", "target": "12"}, {"source": "11", "target": "13"}, {"source": "11", "target": "14"}, {"source": "11", "target": "15"}, {"source": "12", "target": "13"}, {"source": "12", "target": "14"}, {"source": "12", "target": "15"}, {"source": "13", "target": "14"}, {"source": "13", "target": "15"}, {"source": "14", "target": "15"}], "year": 2019, "authorId": {"0": "Seidel,Hans-Peter", "1": "Yu,Hyeonseung", "2": "Bemana,Mojtaba", "3": "Wernikowski,Marek", "4": "Chwesiuk,Michal", "5": "Tursun,OkanTarhan", "6": "Singh,Gurprit", "7": "Myszkowski,Karol", "8": "Mantiuk,Radoslaw", "9": "Didyk,Piotr", "10": "Xu,Weipeng", "11": "Chatterjee,Avishek", "12": "Zollhofer,Michael", "13": "Rhodin,Helge", "14": "Fua,Pascal", "15": "Theobalt,Christian"}}