{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [1, 0], [1, 2], [1, 3], [1, 4], [1, 5], [2, 1], [2, 0], [2, 3], [2, 4], [2, 5], [3, 1], [3, 0], [3, 2], [3, 4], [3, 5], [4, 1], [4, 0], [4, 2], [4, 3], [4, 5], [5, 1], [5, 0], [5, 2], [5, 3], [5, 4]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5"}, "count": 1, "cite": 3, "position": 2.0, "connect": 1.0, "totalConnect": 2.0, "totalCount": 0.16666666666666666, "totalCite": 3.0, "totalPosition": 6.0, "paper": [{"title": "Joint Action in a Virtual Environment: Crossing Roads with Risky vs. Safe Human and Agent Partners", "author": ["Jiang,Yuanyuan", "O'Neal,ElizabethE.", "Rahimian,Pooya", "Yon,JunghumPaul", "Plumert,JodieM.", "Kearney,JosephK."], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865945", "keywords": "", "abstract": "This paper examines how people jointly coordinate their decisions and actions with risky vs. safe human and agent road-crossing partners (Fig. 1). The task for participants was to physically cross a steady stream of traffic in a large-screen virtual environment without getting hit by a car. The computer-generated (CG) agent was programmed to be either safe (taking only large gaps) or risky (also taking small gaps). The human partners were classified as safe (taking more large gaps) or risky (also taking some small gaps) based on their average gap size selection. We found that participants in all four conditions preferred to cross with their partner. As a consequence, the riskiness of the partner (both human and agent) influenced the riskiness of participants' gap choices. We also found that participants tightly synchronized their movement with both human and agent partners. The largest differences in performance between those paired with agent vs. human partners occurred on trials when participants crossed different gaps than their partners. This study demonstrates the potential for studying how people interact with CG agents when performing whole-body joint actions using large-screen immersive virtual environments.", "cite": 3, "year": "2019"}], "name": "O'Neal,ElizabethE.", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "1", "target": "4"}, {"source": "1", "target": "5"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "2", "target": "5"}, {"source": "3", "target": "4"}, {"source": "3", "target": "5"}, {"source": "4", "target": "5"}], "year": 2019, "authorId": {"0": "O'Neal,ElizabethE.", "1": "Jiang,Yuanyuan", "2": "Rahimian,Pooya", "3": "Yon,JunghumPaul", "4": "Plumert,JodieM.", "5": "Kearney,JosephK."}}