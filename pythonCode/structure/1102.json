{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [1, 0], [1, 2], [1, 3], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [2, 15], [2, 3], [2, 1], [2, 0], [2, 3], [2, 16], [2, 9], [2, 17], [3, 11], [3, 12], [3, 13], [3, 14], [3, 15], [3, 2], [3, 1], [3, 0], [3, 2], [4, 5], [4, 0], [4, 6], [4, 7], [4, 8], [5, 4], [5, 0], [5, 6], [5, 7], [5, 8], [6, 18], [6, 19], [6, 20], [6, 21], [6, 22], [6, 4], [6, 5], [6, 0], [6, 7], [6, 8], [6, 23], [6, 24], [6, 25], [6, 26], [6, 27], [6, 28], [7, 4], [7, 5], [7, 0], [7, 6], [7, 8], [8, 4], [8, 5], [8, 0], [8, 6], [8, 7]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15", "16": "16", "17": "17", "18": "18", "19": "19", "20": "20", "21": "21", "22": "22", "23": "23", "24": "24", "25": "25", "26": "26", "27": "27", "28": "28"}, "count": 2, "cite": 15, "position": 2.5, "connect": 1.0, "totalConnect": 1.5217391304347827, "totalCount": 0.4482758620689655, "totalCite": 9.307692307692308, "totalPosition": 5.538461538461538, "paper": [{"title": "Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication", "author": ["Srinivasan,Arjun", "Drucker,StevenM.", "Endert,Alex", "Stasko,John"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865145", "keywords": "", "abstract": "Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type. data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voder's design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts.", "cite": 3, "year": "2019"}, {"title": "FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights", "author": ["Hurter,Christophell", "Riche,NathalieHenry", "Drucker,StevenM.", "Cordeil,Maxime", "Alligier,Richard", "Vuillemot,Romain"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865191", "keywords": "", "abstract": "Visualizing 3D trajectories to extract insights about their similarities and spatial configuration is a critical task in several domains. Air traffic controllers for example deal with large quantities of aircrafts routes to optimize safety in airspace and neuroscientists attempt to understand neuronal pathways in the human brain by visualizing bundles of fibers from DTI images. Extracting insights from masses of 3D trajectories is challenging as the multiple three dimensional lines have complex geometries, may overlap, cross or even merge with each other, making it impossible to follow individual ones in dense areas. As trajectories are inherently spatial and three dimensional, we propose FiberClay: a system to display and interact with 3D trajectories in immersive environments. FiberClay renders a large quantity of trajectories in real time using GP-GPU techniques. FiberClay also introduces a new set of interactive techniques for composing complex queries in 3D space leveraging immersive environment controllers and user position. These techniques enable an analyst to select and compare sets of trajectories with specific geometries and data properties. We conclude by discussing insights found using FiberClay with domain experts in air traffic control and neurology.", "cite": 12, "year": "2019"}], "name": "Drucker,StevenM.", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}, {"id": "16"}, {"id": "17"}, {"id": "18"}, {"id": "19"}, {"id": "20"}, {"id": "21"}, {"id": "22"}, {"id": "23"}, {"id": "24"}, {"id": "25"}, {"id": "26"}, {"id": "27"}, {"id": "28"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "2", "target": "9"}, {"source": "2", "target": "10"}, {"source": "2", "target": "11"}, {"source": "2", "target": "12"}, {"source": "2", "target": "13"}, {"source": "2", "target": "14"}, {"source": "2", "target": "15"}, {"source": "2", "target": "3"}, {"source": "2", "target": "16"}, {"source": "2", "target": "17"}, {"source": "3", "target": "11"}, {"source": "3", "target": "12"}, {"source": "3", "target": "13"}, {"source": "3", "target": "14"}, {"source": "3", "target": "15"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "4", "target": "7"}, {"source": "4", "target": "8"}, {"source": "5", "target": "6"}, {"source": "5", "target": "7"}, {"source": "5", "target": "8"}, {"source": "6", "target": "18"}, {"source": "6", "target": "19"}, {"source": "6", "target": "20"}, {"source": "6", "target": "21"}, {"source": "6", "target": "22"}, {"source": "6", "target": "7"}, {"source": "6", "target": "8"}, {"source": "6", "target": "23"}, {"source": "6", "target": "24"}, {"source": "6", "target": "25"}, {"source": "6", "target": "26"}, {"source": "6", "target": "27"}, {"source": "6", "target": "28"}, {"source": "7", "target": "8"}], "year": 2019, "authorId": {"0": "Drucker,StevenM.", "1": "Srinivasan,Arjun", "2": "Endert,Alex", "3": "Stasko,John", "4": "Hurter,Christophell", "5": "Riche,NathalieHenry", "6": "Cordeil,Maxime", "7": "Alligier,Richard", "8": "Vuillemot,Romain", "9": "Saket,Bahador", "10": "Demiralp,Cagatay", "11": "Wall,Emily", "12": "Agnihotri,Meeshu", "13": "Matzen,Laura", "14": "Divis,Kristin", "15": "Haass,Michael", "16": "Sarvghad,Ali", "17": "Weibel,Nadir", "18": "Yang,Yalong", "19": "Dwyer,Tim", "20": "Jenny,Bernhard", "21": "Marriott,Kim", "22": "Chen,Haohui", "23": "Sicat,Ronell", "24": "Li,Jiabao", "25": "Choi,JunYoung", "26": "Jeong,Won-Ki", "27": "Bach,Benjamin", "28": "Pfister,Hanspeter"}}