{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [1, 2], [1, 0], [1, 3], [1, 4], [2, 1], [2, 0], [2, 3], [2, 4], [3, 1], [3, 2], [3, 0], [3, 4], [4, 1], [4, 2], [4, 0], [4, 3], [4, 13], [4, 14], [4, 15], [4, 16], [4, 17], [4, 18], [4, 19], [4, 20], [4, 21], [4, 22], [4, 23], [4, 24], [5, 0], [5, 6], [5, 7], [5, 8], [5, 9], [5, 25], [5, 26], [5, 8], [6, 5], [6, 0], [6, 7], [6, 8], [6, 9], [7, 5], [7, 0], [7, 6], [7, 8], [7, 9], [8, 5], [8, 0], [8, 6], [8, 7], [8, 9], [8, 27], [8, 28], [8, 25], [8, 5], [8, 26], [9, 5], [9, 0], [9, 6], [9, 7], [9, 8], [10, 11], [10, 0], [10, 12], [11, 10], [11, 0], [11, 12], [12, 10], [12, 11], [12, 0]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15", "16": "16", "17": "17", "18": "18", "19": "19", "20": "20", "21": "21", "22": "22", "23": "23", "24": "24", "25": "25", "26": "26", "27": "27", "28": "28"}, "count": 3, "cite": 8, "position": 2.6666666666666665, "connect": 1.0, "totalConnect": 1.6734693877551021, "totalCount": 0.6896551724137931, "totalCite": 5.6, "totalPosition": 5.8, "paper": [{"title": "Active arrangement of small objects in 3D indoor scenes.", "author": ["Zhang,Suiyun", "Han,Zhizhong", "Lai,Yu-Kun", "Zwicker,Matthias", "Zhang,Hui"], "soname": "IEEE transactions on visualization and computer graphics", "DOI": "10.1109/TVCG.2019.2949295", "keywords": "", "abstract": "Small object arrangement is very important for creating detailed and realistic 3D indoor scenes. In this paper, we present an interactive framework based on active learning to help users create customized arrangements for small objects according to their preferences. To achieve this with minimal user effort, we first learn the prior knowledge about small object arrangement from a 3D indoor scene dataset through a probability mining method, which forms the initial guidance for arranging small objects. Then, users are able to express their preferences on a few small object categories, which are automatically propagated to all the other categories via a novel active learning approach.In the propagation process, we introduce a novel metric to obtain the propagation weights, which measures the degree of interchangeability between two small object categories, and is calculated based on a spatial embedding model learned from the small object neighborhood information extracted from the 3D indoor scene dataset. Experiments show that our framework is able to help users effectively create customized small object arrangements with little effort.", "cite": 0, "year": "2019"}, {"title": "Sparse Data Driven Mesh Deformation.", "author": ["Gao,Lin", "Lai,Yu-Kun", "Yang,Jie", "Ling-Xiao,Zhang", "Xia,Shihong", "Kobbelt,Leif"], "soname": "IEEE transactions on visualization and computer graphics", "DOI": "10.1109/TVCG.2019.2941200", "keywords": "", "abstract": "Example-based mesh deformation methods are powerful tools for realistic shape editing. However, existing techniques typically combine all the example deformation modes, which can lead to overfitting, i.e. using an overly complicated model to explain the user-specified deformation. This leads to implausible or unstable deformation results, including unexpected global changes outside the region of interest. To address this fundamental limitation, we propose a sparse blending method that automatically selects a smaller number of deformation modes to compactly describe the desired deformation. This along with a suitably chosen deformation basis including spatially localized deformation modes leads to significant advantages, including more meaningful, reliable, and efficient deformations because fewer and localized deformation modes are applied. To cope with large rotations, we develop a simple but effective representation based on polar decomposition of deformation gradients, which resolves the ambiguity of large global rotations using an as-consistent-as-possible global optimization. This simple representation has a closed form solution for derivatives, making it efficient for our sparse localized representation and thus ensuring interactive performance. Experimental results show that our method outperforms state-of-the-art data-driven mesh deformation methods, for both quality of results and efficiency.", "cite": 3, "year": "2019"}, {"title": "Robust Non-Rigid Registration with Reweighted Position and Transformation Sparsity", "author": ["Li,Kun", "Yang,Jingyu", "Lai,Yu-Kun", "Guo,Daoliang"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2832136", "keywords": "", "abstract": "Non-rigid registration is challenging because it is ill-posed with high degrees of freedom and is thus sensitive to noise and outliers. We propose a robust non-rigid registration method using reweighted sparsities on position and transformation to estimate the deformations between 3-D shapes. We formulate the energy function with position and transformation sparsity on both the data term and the smoothness term, and define the smoothness constraint using local rigidity. The double sparsity based non-rigid registration model is enhanced with a reweighting scheme, and solved by transferring the model into four alternately-optimized subproblems which have exact solutions and guaranteed convergence. Experimental results on both public datasets and real scanned datasets show that our method outperforms the state-of-the-art methods and is more robust to noise and outliers than conventional non-rigid registration methods.", "cite": 5, "year": "2019"}], "name": "Lai,Yu-Kun", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}, {"id": "16"}, {"id": "17"}, {"id": "18"}, {"id": "19"}, {"id": "20"}, {"id": "21"}, {"id": "22"}, {"id": "23"}, {"id": "24"}, {"id": "25"}, {"id": "26"}, {"id": "27"}, {"id": "28"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "0", "target": "11"}, {"source": "0", "target": "12"}, {"source": "1", "target": "2"}, {"source": "1", "target": "3"}, {"source": "1", "target": "4"}, {"source": "2", "target": "3"}, {"source": "2", "target": "4"}, {"source": "3", "target": "4"}, {"source": "4", "target": "13"}, {"source": "4", "target": "14"}, {"source": "4", "target": "15"}, {"source": "4", "target": "16"}, {"source": "4", "target": "17"}, {"source": "4", "target": "18"}, {"source": "4", "target": "19"}, {"source": "4", "target": "20"}, {"source": "4", "target": "21"}, {"source": "4", "target": "22"}, {"source": "4", "target": "23"}, {"source": "4", "target": "24"}, {"source": "5", "target": "6"}, {"source": "5", "target": "7"}, {"source": "5", "target": "8"}, {"source": "5", "target": "9"}, {"source": "5", "target": "25"}, {"source": "5", "target": "26"}, {"source": "6", "target": "7"}, {"source": "6", "target": "8"}, {"source": "6", "target": "9"}, {"source": "7", "target": "8"}, {"source": "7", "target": "9"}, {"source": "8", "target": "9"}, {"source": "8", "target": "27"}, {"source": "8", "target": "28"}, {"source": "8", "target": "25"}, {"source": "8", "target": "26"}, {"source": "10", "target": "11"}, {"source": "10", "target": "12"}, {"source": "11", "target": "12"}], "year": 2019, "authorId": {"0": "Lai,Yu-Kun", "1": "Zhang,Suiyun", "2": "Han,Zhizhong", "3": "Zwicker,Matthias", "4": "Zhang,Hui", "5": "Gao,Lin", "6": "Yang,Jie", "7": "Ling-Xiao,Zhang", "8": "Xia,Shihong", "9": "Kobbelt,Leif", "10": "Li,Kun", "11": "Yang,Jingyu", "12": "Guo,Daoliang", "13": "Wu,Yingcai", "14": "Xie,Xiao", "15": "Wang,Jiachen", "16": "Deng,Dazhen", "17": "Liang,Hongye", "18": "Cheng,Shoubin", "19": "Chen,Wei", "20": "Frey,Steffen", "21": "Steeb,Holger", "22": "Uribe,David", "23": "Ertl,Thomas", "24": "Wang,Wenping", "25": "Yuan,Ming-Ze", "26": "Fu,Hongbo", "27": "Wang,Zhiyong", "28": "Chai,Jinxiang"}}