{"edges": [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 8], [0, 11], [0, 1], [0, 12], [1, 0], [1, 2], [1, 11], [1, 0], [1, 12], [2, 1], [2, 0], [2, 13], [3, 4], [3, 5], [3, 6], [3, 7], [3, 0], [3, 8], [4, 3], [4, 5], [4, 6], [4, 7], [4, 0], [4, 8], [5, 3], [5, 4], [5, 6], [5, 7], [5, 0], [5, 8], [6, 3], [6, 4], [6, 5], [6, 7], [6, 0], [6, 8], [7, 3], [7, 4], [7, 5], [7, 6], [7, 0], [7, 8], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 0], [8, 9], [8, 10], [8, 0], [9, 10], [9, 0], [9, 8], [10, 9], [10, 0], [10, 8], [10, 14], [10, 15], [10, 16], [10, 17], [10, 18], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 0], [8, 9], [8, 10], [8, 0], [11, 1], [11, 0], [11, 12], [1, 0], [1, 2], [1, 11], [1, 0], [1, 12], [12, 11], [12, 1], [12, 0]], "features": {"0": "0", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "10": "10", "11": "11", "12": "12", "13": "13", "14": "14", "15": "15", "16": "16", "17": "17", "18": "18"}, "count": 4, "cite": 17, "position": 3.5, "connect": 1.1666666666666667, "totalConnect": 2.3, "totalCount": 0.42105263157894735, "totalCite": 11.5, "totalPosition": 4.875, "paper": [{"title": "Task-Based Effectiveness of Basic Visualizations", "author": ["Saket,Bahador", "Endert,Alex", "Demiralp,Cagatay"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2829750", "keywords": "", "abstract": "Visualizations of tabular data are widely used; understanding their effectiveness in different task and data contexts is fundamental to scaling their impact. However, little is known about how basic tabular data visualizations perform across varying data analysis tasks. In this paper, we report results from a crowdsourced experiment to evaluate the effectiveness of five small scale (5-34 data points) two-dimensional visualization types-Table, Line Chart, Bar Chart, Scatterplot, and Pie Chart-across ten common data analysis tasks using two datasets. We find the effectiveness of these visualization types significantly varies across task, suggesting that visualization design would benefit from considering context-dependent effectiveness. Based on our findings, we derive recommendations on which visualizations to choose based on different tasks. We finally train a decision tree on the data we collected to drive a recommender, showcasing how to effectively engineer experimental user data into practical visualization systems.", "cite": 7, "year": "2019"}, {"title": "A Heuristic Approach to Value-Driven Evaluation of Visualizations", "author": ["Wall,Emily", "Agnihotri,Meeshu", "Matzen,Laura", "Divis,Kristin", "Haass,Michael", "Endert,Alex", "Stasko,John"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865146", "keywords": "", "abstract": "Recently, an approach for determining the value of a visualization was proposed, one moving beyond simple measurements of task accuracy and speed. The value equation contains components for the time savings a visualization provides, the insights and insightful questions it spurs, the overall essence of the data it conveys, and the confidence about the data and its domain it inspires. This articulation of value is purely descriptive, however. providing no actionable method of assessing a visualization's value. In this work, we create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations. We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics. We conducted an initial trial of the methodology on three interactive visualizations of the same data set, each evaluated by 15 visualization experts. We found that the methodology showed promise, obtaining consistent ratings across the three visualizations and mirroring judgments of the utility of the visualizations by instructors of the course in which they were developed.", "cite": 5, "year": "2019"}, {"title": "Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication", "author": ["Srinivasan,Arjun", "Drucker,StevenM.", "Endert,Alex", "Stasko,John"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865145", "keywords": "", "abstract": "Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type. data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voder's design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts.", "cite": 3, "year": "2019"}, {"title": "Embedded Merge & Split: Visual Adjustment of Data Grouping", "author": ["Sarvghad,Ali", "Saket,Bahador", "Endert,Alex", "Weibel,Nadir"], "soname": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS", "DOI": "10.1109/TVCG.2018.2865075", "keywords": "", "abstract": "Data grouping is among the most frequently used operations in data visualization. It is the process through which relevant information is gathered, simplified, and expressed in summary form. Many popular visualization tools support automatic grouping of data (e.g., dividing up a numerical variable into bins). Although grouping plays a pivotal role in supporting data exploration, further adjustment and customization of auto-generated grouping criteria is non-trivial. Such adjustments are currently performed either programmatically or through menus and dialogues which require specific parameter adjustments over several steps. In response, we introduce Embedded Merge & Split (EMS), a new interaction technique for direct adjustment of data grouping criteria. We demonstrate how the EMS technique can be designed to directly manipulate width and position in bar charts and histograms, as a means for adjustment of data grouping criteria. We also offer a set of design guidelines for supporting EMS. Finally, we present the results of two user studies, providing initial evidence that EMS can significantly reduce interaction time compared to WIMP-based technique and was subjectively preferred by participants.", "cite": 2, "year": "2019"}], "name": "Endert,Alex", "nodes": [{"id": "0"}, {"id": "1"}, {"id": "2"}, {"id": "3"}, {"id": "4"}, {"id": "5"}, {"id": "6"}, {"id": "7"}, {"id": "8"}, {"id": "9"}, {"id": "10"}, {"id": "11"}, {"id": "12"}, {"id": "13"}, {"id": "14"}, {"id": "15"}, {"id": "16"}, {"id": "17"}, {"id": "18"}], "edgess": [{"source": "0", "target": "1"}, {"source": "0", "target": "2"}, {"source": "0", "target": "3"}, {"source": "0", "target": "4"}, {"source": "0", "target": "5"}, {"source": "0", "target": "6"}, {"source": "0", "target": "7"}, {"source": "0", "target": "8"}, {"source": "0", "target": "9"}, {"source": "0", "target": "10"}, {"source": "0", "target": "11"}, {"source": "0", "target": "12"}, {"source": "1", "target": "2"}, {"source": "1", "target": "11"}, {"source": "1", "target": "12"}, {"source": "2", "target": "13"}, {"source": "3", "target": "4"}, {"source": "3", "target": "5"}, {"source": "3", "target": "6"}, {"source": "3", "target": "7"}, {"source": "3", "target": "8"}, {"source": "4", "target": "5"}, {"source": "4", "target": "6"}, {"source": "4", "target": "7"}, {"source": "4", "target": "8"}, {"source": "5", "target": "6"}, {"source": "5", "target": "7"}, {"source": "5", "target": "8"}, {"source": "6", "target": "7"}, {"source": "6", "target": "8"}, {"source": "7", "target": "8"}, {"source": "8", "target": "9"}, {"source": "8", "target": "10"}, {"source": "9", "target": "10"}, {"source": "10", "target": "14"}, {"source": "10", "target": "15"}, {"source": "10", "target": "16"}, {"source": "10", "target": "17"}, {"source": "10", "target": "18"}, {"source": "11", "target": "12"}], "year": 2019, "authorId": {"0": "Endert,Alex", "1": "Saket,Bahador", "2": "Demiralp,Cagatay", "3": "Wall,Emily", "4": "Agnihotri,Meeshu", "5": "Matzen,Laura", "6": "Divis,Kristin", "7": "Haass,Michael", "8": "Stasko,John", "9": "Srinivasan,Arjun", "10": "Drucker,StevenM.", "11": "Sarvghad,Ali", "12": "Weibel,Nadir", "13": "Cavallo,Marco", "14": "Hurter,Christophell", "15": "Riche,NathalieHenry", "16": "Cordeil,Maxime", "17": "Alligier,Richard", "18": "Vuillemot,Romain"}}